{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: NYC Taxi Data\n",
    "## Machine Learning Model\n",
    "Predict the **total fare amount** of a trip based for the last _3_ months of data (train data on the remaining dataset). The field _fare_amount_ can not be used as a feature in the model.\n",
    "\n",
    "The final model will be assessed using the **RMSE** score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor, GeneralizedLinearRegression\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local spark session\n",
    "spark = SparkSession.builder \\\n",
    "  .appName('nyc-taxi-model') \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters \n",
    "target_field = \"total_amount\"\n",
    "file_loc = \"./output\"\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dataframe(file_loc, cat_cols, num_cols, tgt_col):\n",
    "    # Read data from parquet\n",
    "    df = spark.read.parquet(file_loc)\n",
    "    \n",
    "    # Select only required fields from source and rename target column\n",
    "    if isinstance(tgt_col, list):\n",
    "        select_cols = cat_cols + num_cols + tgt_col\n",
    "    else:\n",
    "        select_cols = cat_cols + num_cols + [tgt_col]   \n",
    "    df = df.select(select_cols).withColumnRenamed(target_field, \"target\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dataframe_glm(file_loc, cat_cols, num_cols, tgt_col):\n",
    "    # Read data from parquet\n",
    "    df = spark.read.parquet(file_loc)\n",
    "    \n",
    "    # Select only required fields from source and rename target column\n",
    "    if isinstance(tgt_col, list):\n",
    "        select_cols = cat_cols + num_cols + tgt_col\n",
    "    else:\n",
    "        select_cols = cat_cols + num_cols + [tgt_col]   \n",
    "    df = df.select(select_cols).withColumnRenamed(target_field, \"label\")\n",
    "    \n",
    "    df= df.withColumn(\"RatecodeID\",df[\"RatecodeID\"].cast(StringType()))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.timlrx.com/blog/feature-selection-using-feature-importance-score-creating-a-pyspark-estimator\n",
    "def get_feature_importance(importance, dataset, features):\n",
    "    list_extract = []\n",
    "    \n",
    "    for i in dataset.schema[features].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[features].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: importance[x])\n",
    "    return(varlist.sort_values('score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataset(df):\n",
    "    df = df.filter((F.col(\"year\") == 2015) | \n",
    "                   (F.col(\"year\") == 2016) & (F.col(\"month\").isin([1,2,3,4,5,6,7,8,9])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset(df):\n",
    "    df = df.filter((F.col(\"year\") == 2016) & (F.col(\"month\").isin([10,11,12])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If model is passed, skip model fit portion and show test results\n",
    "\n",
    "def run_random_forest_model(df, cat_cols, num_cols, trees=20, sub_sample=0.7, feature_imp=True, rf_model= False):\n",
    "    stages = []\n",
    "    \n",
    "    # For category columns implement One Hot Encoding for each field\n",
    "    for col in cat_cols:\n",
    "        column_indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_ind\")\n",
    "        column_encoder = OneHotEncoderEstimator(inputCols=[f\"{col}_ind\"], outputCols=[f\"{col}_ohe\"])\n",
    "        stages += [column_indexer, column_encoder]\n",
    "    \n",
    "    # Create a list of category fields that have been OHE\n",
    "    cat_cols_ohe = [f\"{col}_ohe\" for col in cat_cols]\n",
    "        \n",
    "    # Instantiate a VectorAssembler of all categorical and number columns\n",
    "    assembler = VectorAssembler(inputCols=cat_cols_ohe + num_cols, outputCol='features')\n",
    "    \n",
    "    # Add to stages list\n",
    "    stages += [assembler]\n",
    "    \n",
    "    # Instantiate a pipeline with stages\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    # Fit the pipeline with model data frame\n",
    "    pipeline_model = pipeline.fit(df)\n",
    "        \n",
    "    # Get test/train data\n",
    "    train_data = get_train_dataset(df)\n",
    "    test_data = get_test_dataset(df)\n",
    "    \n",
    "    #test_data.show(20)\n",
    "    #train_data.show(20)\n",
    "\n",
    "    \n",
    "    # Apply the pipeline to the dataframe\n",
    "    test_data = pipeline_model.transform(test_data)\n",
    "    train_data = pipeline_model.transform(train_data)\n",
    "\n",
    "    # Train a Random Forest model to predict the target field\n",
    "    rf = RandomForestRegressor(featuresCol='features', labelCol='target', seed=77,\n",
    "                               numTrees=trees, subsamplingRate=sub_sample)\n",
    "\n",
    "    # if there is no model passed\n",
    "    if not rf_model:\n",
    "        # Use the training data to create a model\n",
    "        rf_model = rf.fit(train_data)\n",
    "        \n",
    "    # Test the model using 3 months of trip data\n",
    "    rf_test = rf_model.transform(test_data)\n",
    "    \n",
    "    # Evaluate predictions using the RMSE\n",
    "    evaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    #rmse_train = evaluator.evaluate(rf_train)\n",
    "\n",
    "    rmse_test = evaluator.evaluate(rf_test)\n",
    "\n",
    "    #string = \"The RMSE on the train data is {}\".format(rmse_train)\n",
    "    #print(string)\n",
    "\n",
    "    string = \"The RMSE on the test data is {}\".format(rmse_test)\n",
    "    print(string)\n",
    "\n",
    "    # If required get feature importance\n",
    "    if feature_imp:\n",
    "        df_imp = get_feature_importance(rf_model.featureImportances, train_data, \"features\").head(10)\n",
    "        display(df_imp)\n",
    "        \n",
    "    return rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If model is passed, skip model fit portion and show test results\n",
    "def run_glm_model(df, cat_cols, num_cols, show_summary=True, model=False):\n",
    "    stages = []\n",
    "    \n",
    "    # For category columns implement One Hot Encoding for each field\n",
    "    for col in cat_cols:\n",
    "        column_indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_ind\")\n",
    "        column_encoder = OneHotEncoderEstimator(inputCols=[f\"{col}_ind\"], outputCols=[f\"{col}_ohe\"])\n",
    "        stages += [column_indexer, column_encoder]\n",
    "    \n",
    "    # Create a list of category fields that have been OHE\n",
    "    cat_cols_ohe = [f\"{col}_ohe\" for col in cat_cols]\n",
    "        \n",
    "    # Instantiate a VectorAssembler of all categorical and number columns\n",
    "    assembler = VectorAssembler(inputCols=cat_cols_ohe + num_cols, outputCol='features')\n",
    "    \n",
    "    # Add to stages list\n",
    "    stages += [assembler]\n",
    "    \n",
    "    # Instantiate a pipeline with stages\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    # Fit the pipeline with model data frame\n",
    "    pipeline_model = pipeline.fit(df)\n",
    "        \n",
    "    # Get test/train data\n",
    "    train_data = get_train_dataset(df)\n",
    "    test_data = get_test_dataset(df)\n",
    "\n",
    "    \n",
    "    # Apply the pipeline to the dataframe\n",
    "    test_data = pipeline_model.transform(test_data)\n",
    "    train_data = pipeline_model.transform(train_data)\n",
    "        \n",
    "    #test_data.show(20)\n",
    "    #train_data.show(20)\n",
    "\n",
    "    # Train a Random Forest model to predict the target field\n",
    "    glm= GeneralizedLinearRegression(family= \"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)\n",
    "    \n",
    "    # if there is no model passed\n",
    "    if not model:\n",
    "        # Use the training data to create a model\n",
    "        model = glm.fit(train_data)\n",
    "\n",
    "    # If required get feature importance\n",
    "    if show_summary:\n",
    "        # Print the coefficients and intercept for generalized linear regression model\n",
    "        print(\"Coefficients: \" + str(model.coefficients))\n",
    "        print(\"Intercept: \" + str(model.intercept))\n",
    "\n",
    "        # Summarize the model over the training set and print out some metrics\n",
    "        summary = model.summary\n",
    "#         print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "#         print(\"T Values: \" + str(summary.tValues))\n",
    "#         print(\"P Values: \" + str(summary.pValues))\n",
    "#         print(\"Dispersion: \" + str(summary.dispersion))\n",
    "#         print(\"Null Deviance: \" + str(summary.nullDeviance))\n",
    "#         print(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "#         print(\"Deviance: \" + str(summary.deviance))\n",
    "#         print(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\n",
    "#         print(\"AIC: \" + str(summary.aic))\n",
    "#         print(\"Deviance Residuals: \")\n",
    "        summary.residuals().show()\n",
    "    \n",
    "        \n",
    "    glm_train = model.transform(train_data)\n",
    "    \n",
    "    # Test the model using 3 months of trip data\n",
    "    glm_test = model.transform(test_data)\n",
    "    \n",
    "    glm_test.show(10)\n",
    "    \n",
    "    # Evaluate predictions using the RMSE\n",
    "    evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    #rmse_train = evaluator.evaluate(glm_train)\n",
    "\n",
    "    rmse_test = evaluator.evaluate(glm_test)\n",
    "\n",
    "    #string = \"The RMSE on the train data is {}\".format(rmse_train)\n",
    "    #print(string)\n",
    "\n",
    "    string = \"The RMSE on the test data is {}\".format(rmse_test)\n",
    "    print(string)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test data is 42.971363475269825\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.423914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>duration_mins</td>\n",
       "      <td>0.301928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>cat_duration_ohe_Above 30 mins</td>\n",
       "      <td>0.128983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>RatecodeID_ohe_1</td>\n",
       "      <td>0.054579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>RatecodeID_ohe_2</td>\n",
       "      <td>0.025638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>cat_duration_ohe_20-30 mins</td>\n",
       "      <td>0.018803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cat_duration_ohe_5-10 mins</td>\n",
       "      <td>0.015180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>RatecodeID_ohe_3</td>\n",
       "      <td>0.015043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cat_duration_ohe_10-20 mins</td>\n",
       "      <td>0.007072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>RatecodeID_ohe_5</td>\n",
       "      <td>0.005579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                            name     score\n",
       "0    10                   trip_distance  0.423914\n",
       "1    11                   duration_mins  0.301928\n",
       "5     3  cat_duration_ohe_Above 30 mins  0.128983\n",
       "7     5                RatecodeID_ohe_1  0.054579\n",
       "8     6                RatecodeID_ohe_2  0.025638\n",
       "4     2     cat_duration_ohe_20-30 mins  0.018803\n",
       "3     1      cat_duration_ohe_5-10 mins  0.015180\n",
       "10    8                RatecodeID_ohe_3  0.015043\n",
       "2     0     cat_duration_ohe_10-20 mins  0.007072\n",
       "9     7                RatecodeID_ohe_5  0.005579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First model test- This was a prelimilary test with unclean data\n",
    "category_columns = [\"cat_duration\", \"taxi_colour\", \"RatecodeID\"]\n",
    "number_columns = [\"trip_distance\", \"duration_mins\"]\n",
    "\n",
    "# Read data from parquet\n",
    "df_model = create_model_dataframe(file_loc, category_columns, number_columns, target_field)\n",
    "\n",
    "# Run random forest model\n",
    "m1 = run_random_forest_model(df_model, category_columns, number_columns, feature_imp=True)\n",
    "\n",
    "# test the random forest model\n",
    "test_model(m1, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test data is 4.063293506704049\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.562030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>duration_mins</td>\n",
       "      <td>0.204166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>RatecodeID_ohe_1</td>\n",
       "      <td>0.162982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RatecodeID_ohe_2</td>\n",
       "      <td>0.053931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>RatecodeID_ohe_3</td>\n",
       "      <td>0.011078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>RatecodeID_ohe_5</td>\n",
       "      <td>0.005101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>RatecodeID_ohe_4</td>\n",
       "      <td>0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx              name     score\n",
       "0    5     trip_distance  0.562030\n",
       "1    6     duration_mins  0.204166\n",
       "3    0  RatecodeID_ohe_1  0.162982\n",
       "4    1  RatecodeID_ohe_2  0.053931\n",
       "6    3  RatecodeID_ohe_3  0.011078\n",
       "5    2  RatecodeID_ohe_5  0.005101\n",
       "7    4  RatecodeID_ohe_4  0.000668\n",
       "2    7   passenger_count  0.000044"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Second model test- After major data cleaning\n",
    "category_columns = [\"RatecodeID\"]\n",
    "number_columns = [\"trip_distance\", \"duration_mins\", \"passenger_count\"]\n",
    "\n",
    "# Read data from parquet\n",
    "df_model = create_model_dataframe(file_loc, category_columns, number_columns, target_field)\n",
    "\n",
    "# Run random forest model\n",
    "m2 = run_random_forest_model(df_model, category_columns, number_columns, feature_imp=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third model test to try out GLM model with EDA results\n",
    "category_columns = [\"RatecodeID\"]\n",
    "number_columns = [\"trip_distance\"]\n",
    "\n",
    "# Read data from parquet\n",
    "df_model = create_model_dataframe_glm(file_loc, category_columns, number_columns, target_field)\n",
    "\n",
    "# Run random forest model\n",
    "m3 = run_glm_model(df_model, category_columns, number_columns, show_summary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----+--------------+--------------+--------------------+\n",
      "|RatecodeID|trip_distance|label|RatecodeID_ind|RatecodeID_ohe|            features|\n",
      "+----------+-------------+-----+--------------+--------------+--------------------+\n",
      "|         1|          3.7| 17.0|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,3.7...|\n",
      "|         1|         1.35|12.96|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,1.3...|\n",
      "|         1|          0.7| 6.95|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,0.6...|\n",
      "|         1|         0.79| 7.54|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,0.7...|\n",
      "|         1|          1.2| 9.35|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,1.2...|\n",
      "|         1|         0.81| 7.56|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,0.8...|\n",
      "|         1|         2.07| 13.5|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,2.0...|\n",
      "|         1|         1.17|  9.8|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,1.1...|\n",
      "|         1|         9.53| 31.8|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,9.5...|\n",
      "|         1|         0.99|  6.8|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,0.9...|\n",
      "|         1|         4.98|20.16|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,4.9...|\n",
      "|         2|         17.3|58.34|           1.0| (5,[1],[1.0])|(6,[1,5],[1.0,17....|\n",
      "|         1|         2.81| 14.3|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,2.8...|\n",
      "|         1|         13.5| 48.3|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,13.5])|\n",
      "|         1|         1.17|  6.8|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,1.1...|\n",
      "|         1|         2.44| 14.8|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,2.4...|\n",
      "|         2|        18.92|63.36|           1.0| (5,[1],[1.0])|(6,[1,5],[1.0,18....|\n",
      "|         1|         1.38|11.76|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,1.3...|\n",
      "|         1|         1.06|  7.8|           0.0| (5,[0],[1.0])|(6,[0,5],[1.0,1.0...|\n",
      "|         2|        18.44|70.01|           1.0| (5,[1],[1.0])|(6,[1,5],[1.0,18....|\n",
      "+----------+-------------+-----+--------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Coefficients: [-2.2643259208194513,-1.16753244724682,9.075921347538968,27.272433119881384,10.05567526657283,3.192111335099057]\n",
      "Intercept: 8.522572067072046\n",
      "+--------------------+\n",
      "|   devianceResiduals|\n",
      "+--------------------+\n",
      "| -1.0690582383308325|\n",
      "|   2.392403513404787|\n",
      "|  -1.542724233503865|\n",
      "| -1.2400142076231013|\n",
      "| -0.7387795191134661|\n",
      "| -1.2838563925138757|\n",
      "|  0.6340836031887775|\n",
      "|-0.19301608059307185|\n",
      "| -4.8790670803003735|\n",
      "|  -2.618436207708143|\n",
      "|  -1.994960808518485|\n",
      "|  -4.238563129063351|\n",
      "| -0.9280786244920058|\n",
      "| -1.0517499330293205|\n",
      "|  -3.193016080593072|\n",
      "|  0.7530022041864939|\n",
      "|  -4.389785713086596|\n",
      "|  1.0966404554137164|\n",
      "| -1.8418837880686567|\n",
      "|  3.7924277924072527|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "The RMSE on the test data is 4.5209452335053255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneralizedLinearRegression_a87d194a52d7"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_glm_model(df_model, category_columns, number_columns, show_summary=True, model= m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-7.822053861412036,5.383078802045187,6.517288065879361,36.03416184374301,19.78894809613916,0.8132444648866406,0.661961517551023]\n",
      "Intercept: 4.01573956849732\n",
      "+-------------------+\n",
      "|  devianceResiduals|\n",
      "+-------------------+\n",
      "|-1.1947683598096326|\n",
      "|  1.841642121381259|\n",
      "|0.23315204788496047|\n",
      "| 0.5814140017314369|\n",
      "|0.39756231825612254|\n",
      "|  1.111530591801861|\n",
      "| 0.9159718458957968|\n",
      "|0.20545336534492797|\n",
      "|-0.8507354406985854|\n",
      "|-1.2628613879745316|\n",
      "|-2.7643839958030476|\n",
      "|-0.6586232308316653|\n",
      "| -1.028653143952262|\n",
      "| -5.735620881399413|\n",
      "| -4.195183935318356|\n",
      "| -1.097328917697034|\n",
      "|  4.297720664225423|\n",
      "| 1.5325624030928733|\n",
      "|-1.4517184254238416|\n",
      "| -4.558611070077987|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "The RMSE on the test data is 4.330131515586314\n"
     ]
    }
   ],
   "source": [
    "# Fourth model test to try out GLM with a different set of features\n",
    "category_columns = [\"RatecodeID\"]\n",
    "number_columns = [\"duration_mins\", \"speed_mph\"]\n",
    "\n",
    "# Read data from parquet\n",
    "df_model = create_model_dataframe_glm(file_loc, category_columns, number_columns, target_field)\n",
    "\n",
    "# Run random forest model\n",
    "m4 = run_glm_model(df_model, category_columns, number_columns, show_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
