{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: NYC Taxi Data\n",
    "## Machine Learning Model\n",
    "Predict the **total fare amount** of a trip based for the last _3_ months of data (train data on the remaining dataset). The field _fare_amount_ can not be used as a feature in the model.\n",
    "\n",
    "The final model will be assessed using the **RMSE** score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local spark session\n",
    "spark = SparkSession.builder \\\n",
    "  .appName('nyc-taxi-model') \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters \n",
    "target_field = \"total_amount\"\n",
    "category_columns = [\"trip_duration_category\"]\n",
    "number_columns = [\"trip_distance_km\",\"trip_duration_seconds\",\"pickup_hour\",\"month\",\"year\",\"passenger_count\"]\n",
    "gbt_num_cols = [\"trip_distance_km\",\"trip_duration_seconds\"]\n",
    "file_loc = \"./output\"\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dataframe(file_loc, cat_cols, num_cols, tgt_col):\n",
    "    # Read data from parquet\n",
    "    df = spark.read.parquet(file_loc)\n",
    "    \n",
    "    # Select only required fields from source and rename target column\n",
    "    if isinstance(tgt_col, list):\n",
    "        select_cols = cat_cols + num_cols + tgt_col\n",
    "    else:\n",
    "        select_cols = cat_cols + num_cols + [tgt_col]   \n",
    "    df = df.select(select_cols).withColumnRenamed(target_field, \"target\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.timlrx.com/blog/feature-selection-using-feature-importance-score-creating-a-pyspark-estimator\n",
    "def get_feature_importance(importance, dataset, features):\n",
    "    list_extract = []\n",
    "    \n",
    "    for i in dataset.schema[features].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[features].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: importance[x])\n",
    "    return(varlist.sort_values('score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataset(df):\n",
    "    df = df.filter((F.col(\"year\") == 2017) | \n",
    "                   (F.col(\"year\") == 2018) & (F.col(\"month\").isin([1,2,3,4,5,6,7,8,9])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset(df):\n",
    "    df = df.filter((F.col(\"year\") == 2018) & (F.col(\"month\").isin([10,11,12])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest_model(df, cat_cols, num_cols, trees=20, sub_sample=0.7, feature_imp=True):\n",
    "    stages = []\n",
    "           \n",
    "    # For category columns implement One Hot Encoding for each field\n",
    "    for col in cat_cols:\n",
    "        column_indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_ind\")\n",
    "        column_encoder = OneHotEncoderEstimator(inputCols=[f\"{col}_ind\"], outputCols=[f\"{col}_ohe\"])\n",
    "        stages += [column_indexer, column_encoder]\n",
    "    \n",
    "    # Create a list of category fields that have been OHE\n",
    "    cat_cols_ohe = [f\"{col}_ohe\" for col in cat_cols]\n",
    "    \n",
    "    # Instantiate a VectorAssembler of all categorical and number columns\n",
    "    assembler = VectorAssembler(inputCols=cat_cols_ohe + num_cols, outputCol='features')\n",
    "    \n",
    "    # Add to stages list\n",
    "    stages += [assembler]\n",
    "    \n",
    "    # Instantiate a pipeline with stages\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    # Fit the pipeline with model data frame\n",
    "    pipeline_model = pipeline.fit(df)\n",
    "    \n",
    "    # Get test/train data\n",
    "    train_data = get_train_dataset(df)\n",
    "    test_data = get_test_dataset(df)\n",
    "    \n",
    "    # Apply the pipeline to the dataframe\n",
    "    test_data = pipeline_model.transform(test_data)\n",
    "    train_data = pipeline_model.transform(train_data)\n",
    "    \n",
    "    # Train a Random Forest model to predict the target field\n",
    "    rf = RandomForestRegressor(featuresCol='features', labelCol='target', seed=77,\n",
    "                               numTrees=trees, subsamplingRate=sub_sample)\n",
    "\n",
    "    # Use the training data to create a model\n",
    "    rf_model = rf.fit(train_data)\n",
    "    rf_train = rf_model.transform(train_data)\n",
    "    \n",
    "    # Test the model using 3 months of trip data\n",
    "    rf_test = rf_model.transform(test_data)\n",
    "    \n",
    "    # Evaluate predictions using the RMSE\n",
    "    evaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(rf_test)\n",
    "\n",
    "    string = \"The RMSE on the test data is {}\".format(rmse)\n",
    "    print(string)\n",
    "\n",
    "    # If required get feature importance\n",
    "    if feature_imp:\n",
    "        df_imp = get_feature_importance(rf_model.featureImportances, train_data, \"features\").head(10)\n",
    "        display(df_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test data is 5.57140677904781\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>trip_distance_km</td>\n",
       "      <td>0.512466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>trip_duration_seconds</td>\n",
       "      <td>0.363379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>trip_duration_category_ohe_20-30 mins</td>\n",
       "      <td>0.037776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>trip_duration_category_ohe_10-20 mins</td>\n",
       "      <td>0.032827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>trip_duration_category_ohe_Under 5 mins</td>\n",
       "      <td>0.028285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>trip_duration_category_ohe_5-10 mins</td>\n",
       "      <td>0.023351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>pickup_hour</td>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>year</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>month</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                     name     score\n",
       "0    4                         trip_distance_km  0.512466\n",
       "1    5                    trip_duration_seconds  0.363379\n",
       "9    3    trip_duration_category_ohe_20-30 mins  0.037776\n",
       "6    0    trip_duration_category_ohe_10-20 mins  0.032827\n",
       "8    2  trip_duration_category_ohe_Under 5 mins  0.028285\n",
       "7    1     trip_duration_category_ohe_5-10 mins  0.023351\n",
       "2    6                              pickup_hour  0.001379\n",
       "4    8                                     year  0.000314\n",
       "5    9                          passenger_count  0.000171\n",
       "3    7                                    month  0.000051"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read data from parquet\n",
    "df_model = create_model_dataframe(file_loc, category_columns, number_columns, target_field)\n",
    "\n",
    "# Run random forest model\n",
    "run_random_forest_model(df_model, category_columns, number_columns, feature_imp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gb_tree_model(df, cat_cols, num_cols, max_depth=5, max_iterations=20):\n",
    "    stages = []\n",
    "           \n",
    "    # For category columns implement One Hot Encoding for each field\n",
    "    for col in cat_cols:\n",
    "        column_indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_ind\")\n",
    "        column_encoder = OneHotEncoderEstimator(inputCols=[f\"{col}_ind\"], outputCols=[f\"{col}_ohe\"])\n",
    "        stages += [column_indexer, column_encoder]\n",
    "    \n",
    "    # Create a list of category fields that have been OHE\n",
    "    cat_cols_ohe = [f\"{col}_ohe\" for col in cat_cols]\n",
    "    \n",
    "    # Instantiate a VectorAssembler of all categorical and number columns\n",
    "    assembler = VectorAssembler(inputCols=cat_cols_ohe + num_cols, outputCol='features')\n",
    "    \n",
    "    # Add to stages list\n",
    "    stages += [assembler]\n",
    "    \n",
    "    # Instantiate a pipeline with stages\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    # Fit the pipeline with model data frame\n",
    "    pipeline_model = pipeline.fit(df)\n",
    "    \n",
    "    # Get test/train data\n",
    "    train_data = get_train_dataset(df)\n",
    "    test_data = get_test_dataset(df)\n",
    "    \n",
    "    # Apply the pipeline to the dataframe\n",
    "    test_data = pipeline_model.transform(test_data)\n",
    "    train_data = pipeline_model.transform(train_data)\n",
    "    \n",
    "    # Train a Random Forest model to predict the target field\n",
    "    gbt = GBTRegressor(featuresCol='features', labelCol='target', seed= 77,\n",
    "                       maxDepth=max_depth, maxIter=max_iterations)\n",
    "\n",
    "    # Use the training data to create a model\n",
    "    gbt_model = gbt.fit(train_data)\n",
    "    gbt_train = gbt.transform(train_data)\n",
    "    \n",
    "    # Test the model using 3 months of trip data\n",
    "    gbt_test = gbt_model.transform(test_data)\n",
    "    \n",
    "    # Evaluate predictions using the RMSE\n",
    "    evaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(gbt_test)\n",
    "\n",
    "    string = \"The RMSE on the test data is {}\".format(rmse)\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from parquet\n",
    "df_model = create_model_dataframe(file_loc, category_columns, gbt_num_cols, target_field)\n",
    "\n",
    "# Run random forest model\n",
    "run_gb_tree_model(df_model, category_columns, gbt_num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
