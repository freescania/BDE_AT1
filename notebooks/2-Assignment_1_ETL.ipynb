{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: NYC Taxi Data\n",
    "\n",
    "ETL processing of NFC TLC dataset. Process written in four parts.\n",
    "\n",
    "1. Extract data from S3\n",
    "2. Transform datatypes and create new features\n",
    "3. Clean data - remove trips with questionable data\n",
    "4. Load data into parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import BooleanType, DoubleType, IntegerType, StringType, StructType, StructField, TimestampType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters \n",
    "bucket_name = \"nyc-tlc\" # s3 bucket name with required nyc tlc files\n",
    "years = [\"2017\", \"2018\"]\n",
    "#tlc_colours = [\"yellow\", \"green\"]\n",
    "tlc_colours = [\"green\"]\n",
    "zone_lookup = \"taxi _zone_lookup.csv\"\n",
    "dt_columns = [\"pickup_datetime\",\"dropoff_datetime\"]\n",
    "int_columns = [\"passenger_count\",\"year\"]\n",
    "num_columns = [\"trip_distance\",\"fare_amount\",\"extra\",\"mta_tax\",\"improvement_surcharge\",\"tip_amount\",\"tolls_amount\",\n",
    "               \"ehail_fee\",\"total_amount\"]\n",
    "initial_columns = [\"VendorID\",\"pickup_datetime\",\"dropoff_datetime\",\"passenger_count\",\"trip_distance\",\"PULocationID\",\n",
    "                 \"DOLocationID\",\"RatecodeID\",\"store_and_fwd_flag\",\"payment_type\",\"fare_amount\",\"extra\",\"mta_tax\",\"improvement_surcharge\",\n",
    "                 \"tip_amount\",\"tolls_amount\",\"ehail_fee\",\"total_amount\",\"trip_type\",\"taxi_type\",\"year\",\"filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local spark session\n",
    "spark = SparkSession.builder \\\n",
    "        .appName('nyc-taxi-etl') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to read S3 bucket\n",
    "# Want to expand this out to be able to create a list of files to extract\n",
    "def bucket_contents_to_list(bucket, match=''):\n",
    "    files = []\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    bucket_resource = s3_resource.Bucket(bucket)\n",
    "    for key in bucket_resource.objects.all():\n",
    "        if match in key.key:\n",
    "            files.append(key.key)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from S3 bucket\n",
    "def extract_data_from_bucket(bucket, year, colour):\n",
    "    df = spark.read.csv(f\"s3a://{bucket}/trip data/{colour}_tripdata_{year}-*.csv\", header=True)\n",
    "    # Add taxi colour and filename to data frame\n",
    "    df = df.withColumn(\"taxi_type\", F.lit(colour)).\\\n",
    "        withColumn(\"year\", F.lit(year)).\\\n",
    "        withColumn(\"filename\", F.input_file_name())\n",
    "    if colour == \"yellow\":\n",
    "        # if extracting yellow taxi trips add trip_type so columns match with green data frame\n",
    "        df = df.withColumn(\"trip_type\",\"1\").\\\n",
    "          withColumn(\"ehail_fee\",\"0\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract lookup data from NYC TLC\n",
    "def extract_lookup_data_from_bucket(bucket, filename):\n",
    "    df = spark.read.csv(f\"s3a://{bucket}/misc/{filename}\", header=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an empty data frame for data loaded from CSV\n",
    "def generate_empty_dataframe():\n",
    "    schema = StructType([\n",
    "      StructField('VendorID', StringType(), True),\n",
    "      StructField('pickup_datetime', StringType(), True),\n",
    "      StructField('dropoff_datetime', StringType(), True),\n",
    "      StructField('passenger_count', StringType(), True),\n",
    "      StructField('trip_distance', StringType(), True),\n",
    "      StructField('PULocationID', StringType(), True),\n",
    "      StructField('DOLocationID', StringType(), True),\n",
    "      StructField('RateCodeID', StringType(), True),\n",
    "      StructField('store_and_fwd_flag', StringType(), True),\n",
    "      StructField('payment_type', StringType(), True),\n",
    "      StructField('fare_amount', StringType(), True),\n",
    "      StructField('extra', StringType(), True),\n",
    "      StructField('mta_tax', StringType(), True),\n",
    "      StructField('improvement_surcharge', StringType(), True),\n",
    "      StructField('tip_amount', StringType(), True),\n",
    "      StructField('tolls_amount', StringType(), True),\n",
    "      StructField('ehail_fee', StringType(), True),\n",
    "      StructField('total_amount', StringType(), True),\n",
    "      StructField('trip_type', StringType(), True),\n",
    "      StructField('taxi_type', StringType(), True),\n",
    "      StructField('year', StringType(), True),\n",
    "      StructField('filename', StringType(), True),\n",
    "      ])\n",
    "\n",
    "    df = spark.createDataFrame([], schema)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trip_duration_category(time):\n",
    "    minutes = time / 60\n",
    "    if minutes < 5:\n",
    "        return \"Under 5 mins\"\n",
    "    elif 5 <= minutes < 10:\n",
    "        return \"5-10 mins\"\n",
    "    elif 10 <= minutes < 20:\n",
    "        return \"10-20 mins\"\n",
    "    elif 20 <= minutes < 30:\n",
    "        return \"20-30 mins\"\n",
    "    else:\n",
    "        return \"Above 30 mins\"\n",
    "\n",
    "# Register function as a Spark user defined function \n",
    "udf_get_trip_duration_category = F.udf(lambda x: get_trip_duration_category(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the month from the filename - maybe more useful than relying on month in datettime fields\n",
    "def get_month_from_filename(filename):\n",
    "    element = filename.split(\"-\")[-1]\n",
    "    month = element.split(\".\")[0]\n",
    "    return month\n",
    "    \n",
    "# Register function as a Spark user defined function \n",
    "udf_get_month_from_filename = F.udf(lambda x: get_month_from_filename(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_location(location):\n",
    "    if location == \"EWR\" or location == \"Airports\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "#Register function as a Spark user defined function\n",
    "udf_get_airport_location = F.udf(lambda x: get_airport_location(x), BooleanType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract NYC Yellow and Green Taxi Cab Data\n",
    "\n",
    "Extract data from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trip data\n",
    "df = generate_empty_dataframe()\n",
    "\n",
    "# Create a data frame with taxi cab data for each applicable year and colour \n",
    "for year in years:\n",
    "    for tlc_colour in tlc_colours:\n",
    "        df_initial = extract_data_from_bucket(bucket_name, year, tlc_colour)\n",
    "        # Standardise names of pickup/dropoff datetime\n",
    "        if tlc_colour == \"yellow\":\n",
    "            df_initial = df_initial.withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\").\\\n",
    "                                  withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "        else:\n",
    "            df_initial = df_initial.withColumnRenamed(\"lpep_pickup_datetime\", \"pickup_datetime\").\\\n",
    "                                  withColumnRenamed(\"lpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "        # Union data dataframes together into one\n",
    "        df_initial = df_initial.select(initial_columns)\n",
    "        df = df.union(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract zone lookup data\n",
    "zone_df = extract_lookup_data_from_bucket(bucket_name, zone_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data\n",
    "### Modify data types\n",
    "\n",
    "* pickup_datetime_string: string -> timestamp\n",
    "* dropoff_datetime_string: string -> timestamp\n",
    "* passenger_count: string -> integer\n",
    "* trip_distance: string -> double\n",
    "* fare_amount: string -> double\n",
    "* extra: string -> double\n",
    "* mta_tax: string -> double\n",
    "* tip_amount: string -> double\n",
    "* tolls_amount: string -> double\n",
    "* improvement_surcharge: string -> double\n",
    "* total_amount: string -> double\n",
    "* ehail_fee: string -> double\n",
    "\n",
    "### Rename Columns\n",
    "\n",
    "* **PULocationID** -> pickup_location_id\n",
    "* **DOLocationID** -> dropof_location_id\n",
    "\n",
    "### Join Datasets\n",
    "\n",
    "* Join trips to zone lookups\n",
    "\n",
    "### Create new features\n",
    "\n",
    "* **taxi_type**: whether is a green or yellow cab - created in extract\n",
    "* **trip_duration**: time, in seconds, between trip start and trip end\n",
    "* **trip_duration_cat**: bins of trip durations; lt 5 Mins, 5-10 mins, 10-20 mins, 20-30 mins, gt 30 mins\n",
    "* **year**: the year the trip took place in - created in extract\n",
    "* **month**: the month the trip took place in\n",
    "* **hour**: the hour the trip took place in\n",
    "* **from_airport**: whether the trip started from either Newark or LaGuardia Airport\n",
    "* **to_airport**: whether the trip ended at either Newark or LaGuardia Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data frame for transforms\n",
    "df_transform = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns that convert datetime strings to a timestamp data type\n",
    "for column in dt_columns:\n",
    "    df_transform = df_transform.withColumn(column, F.col(column).astype(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to integers\n",
    "for column in int_columns:\n",
    "    df_transform = df_transform.withColumn(column, F.col(column).astype(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to numeric\n",
    "for column in num_columns:\n",
    "    df_transform = df_transform.withColumn(column, F.col(column).astype(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df_transform = df_transform.withColumnRenamed(\"PULocationID\",\"pickup_location_id\").\\\n",
    "                            withColumnRenamed(\"DOLocationID\",\"dropoff_location_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join trip data with zone lookup\n",
    "# Now join datasets\n",
    "df_transform = df_transform.join(zone_df\n",
    "                                 ,df_transform.pickup_location_id == zone_df.LocationID\n",
    "                                 ,how=\"left\").\\\n",
    "                            drop(\"LocationID\").\\\n",
    "                            drop(\"Zone\").\\\n",
    "                            withColumnRenamed(\"service_zone\",\"pickup_service_zone\").\\\n",
    "                            withColumnRenamed(\"Borough\",\"pickup_borough\").\\\n",
    "                            join(zone_df\n",
    "                                 ,df_transform.dropoff_location_id == zone_df.LocationID\n",
    "                                 ,how=\"left\").\\\n",
    "                            drop(\"LocationID\").\\\n",
    "                            drop(\"Zone\").\\\n",
    "                            withColumnRenamed(\"service_zone\",\"dropoff_service_zone\").\\\n",
    "                            withColumnRenamed(\"Borough\",\"dropoff_borough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features for trip durtaion (in seconds) and trip category\n",
    "df_transform = df_transform.withColumn(\"trip_duration_seconds\", F.col(\"dropoff_datetime\").cast(\"long\") - F.col(\"pickup_datetime\").cast(\"long\")).\\\n",
    "                    withColumn(\"trip_duration_category\", udf_get_trip_duration_category(F.col(\"trip_duration_seconds\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create field for month of trip based on filename rather than pickup datetime\n",
    "df_transform = df_transform.withColumn(\"month\", udf_get_month_from_filename(F.col(\"filename\")).astype(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create field for hour of trip\n",
    "df_transform = df_transform.withColumn(\"pickup_hour\", F.hour(F.col(\"pickup_datetime\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create field for from airport and to airport features\n",
    "df_transform = df_transform.withColumn(\"from_airport\", udf_get_airport_location(F.col(\"pickup_service_zone\"))).\\\n",
    "                            withColumn(\"to_airport\", udf_get_airport_location(F.col(\"dropoff_service_zone\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Clean\n",
    "### Remove records\n",
    "\n",
    "* **RateCodeID**: trips with a 99 rate code\n",
    "* **fare_amount**: trips with a fare amount of zero or below\n",
    "* **trip_duration_seconds**: trips with a duration of zero, or less, seconds\n",
    "* **pickup_datetime**: outside month of file period\n",
    "* **passenger_count**: where equal to zero change to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data frame for cleaning steps\n",
    "df_clean = df_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records with a 99 rate code id \n",
    "df_clean = df_clean.filter(F.col(\"RateCodeID\") < 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records with a fare_amount of zero or below\n",
    "df_clean = df_clean.filter(F.col(\"fare_amount\") > 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records with a trip duration of 0 seconds or less\n",
    "df_clean = df_clean.filter(F.col(\"trip_duration_seconds\") > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trips that start outside original files remit\n",
    "df_clean = df_clean.filter((F.col(\"year\") == F.year(F.col(\"pickup_datetime\")))\n",
    "                           & (F.col(\"month\") == F.month(F.col(\"pickup_datetime\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make trips with zero passengers equal to the mode for non zero passenger trips, which is 1 based on EDA\n",
    "df_clean = df_clean.withColumn(\"passenger_count\", F.when(df_clean[\"passenger_count\"] == 0, 1).\\\n",
    "                    otherwise(df_clean[\"passenger_count\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data\n",
    "Write data to parquest files for analysis and loading into ML model at later date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.write.partitionBy(\"year\",\"month\").parquet(\"./output\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
