{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: NYC Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local spark session\n",
    "spark = SparkSession.builder \\\n",
    "        .appName('nyc-taxi-sql') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parquet file\n",
    "df = spark.read.load(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"nyc_taxi_data_2017_18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.a. For each year and month: What was the total number of trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------------+\n",
      "|year|month|number_of_trips|\n",
      "+----+-----+---------------+\n",
      "|2017|    1|       10759055|\n",
      "|2017|    2|       10170592|\n",
      "|2017|    3|       11429334|\n",
      "|2017|    4|       11104411|\n",
      "|2017|    5|       11139331|\n",
      "|2017|    6|       10612182|\n",
      "|2017|    7|        9483901|\n",
      "|2017|    8|        9271000|\n",
      "|2017|    9|        9808837|\n",
      "|2017|   10|       10673291|\n",
      "|2017|   11|       10137773|\n",
      "|2017|   12|       10393990|\n",
      "|2018|    1|        9535011|\n",
      "|2018|    2|        9244198|\n",
      "|2018|    3|       10246590|\n",
      "|2018|    4|       10086530|\n",
      "|2018|    5|       10002146|\n",
      "|2018|    6|        9433947|\n",
      "|2018|    7|        8516297|\n",
      "|2018|    8|        8497622|\n",
      "|2018|    9|        8688822|\n",
      "|2018|   10|        9508435|\n",
      "|2018|   11|        8781808|\n",
      "|2018|   12|        8837417|\n",
      "+----+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT year\n",
    ",month\n",
    ",COUNT(*) AS number_of_trips\n",
    "FROM nyc_taxi_data_2017_18\n",
    "GROUP BY year\n",
    ",month\n",
    "ORDER BY year, month\n",
    "\"\"\").show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.b. For each year and month: Which weekday had the most trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------------+-----------+\n",
      "|year|month|pickup_weekday|total_trips|\n",
      "+----+-----+--------------+-----------+\n",
      "|2017|    1|       Tuesday|    1698667|\n",
      "|2017|    2|      Saturday|    1613115|\n",
      "|2017|    3|        Friday|    2030231|\n",
      "|2017|    4|      Saturday|    1965173|\n",
      "|2017|    5|     Wednesday|    1857762|\n",
      "|2017|    6|      Thursday|    1852070|\n",
      "|2017|    7|      Saturday|    1526780|\n",
      "|2017|    8|      Thursday|    1603485|\n",
      "|2017|    9|        Friday|    1721426|\n",
      "|2017|   10|       Tuesday|    1673294|\n",
      "|2017|   11|     Wednesday|    1740282|\n",
      "|2017|   12|        Friday|    1827482|\n",
      "|2018|    1|     Wednesday|    1624943|\n",
      "|2018|    2|        Friday|    1462063|\n",
      "|2018|    3|        Friday|    1808358|\n",
      "|2018|    4|        Monday|    1520937|\n",
      "|2018|    5|      Thursday|    1741622|\n",
      "|2018|    6|        Friday|    1641972|\n",
      "|2018|    7|       Tuesday|    1453861|\n",
      "|2018|    8|     Wednesday|    1485514|\n",
      "|2018|    9|      Saturday|    1469617|\n",
      "|2018|   10|     Wednesday|    1572695|\n",
      "|2018|   11|        Friday|    1520943|\n",
      "|2018|   12|      Saturday|    1505080|\n",
      "+----+-----+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT year\n",
    "    ,month\n",
    "    ,pickup_weekday\n",
    "    ,total_trips\n",
    "FROM (SELECT year\n",
    "        ,month\n",
    "        ,DATE_FORMAT(pickup_datetime, \"EEEE\") AS pickup_weekday\n",
    "        ,COUNT(*) AS total_trips\n",
    "        ,ROW_NUMBER() OVER (PARTITION BY year,month ORDER BY COUNT(*) DESC) AS row_num\n",
    "    FROM nyc_taxi_data_2017_18\n",
    "    GROUP BY year\n",
    "        ,month\n",
    "        ,pickup_weekday\n",
    "    )\n",
    "WHERE row_num = 1\n",
    "ORDER BY year\n",
    "    ,month\n",
    "\"\"\").show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.c. For each year and month: What was the average number of passengers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------------------+\n",
      "|year|month|avg_passengers_per_trip|\n",
      "+----+-----+-----------------------+\n",
      "|2017|    1|     1.6035315369240142|\n",
      "|2017|    2|     1.5991538152351408|\n",
      "|2017|    3|     1.5928098697614401|\n",
      "|2017|    4|     1.6020269782881775|\n",
      "|2017|    5|     1.5956274214313229|\n",
      "|2017|    6|     1.5996936351072757|\n",
      "|2017|    7|     1.6155018910467327|\n",
      "|2017|    8|     1.6097582785028584|\n",
      "|2017|    9|     1.6050604164387685|\n",
      "|2017|   10|     1.5993137449358403|\n",
      "|2017|   11|     1.5957080514625845|\n",
      "|2017|   12|     1.6152579519510795|\n",
      "|2018|    1|     1.5930920268471636|\n",
      "|2018|    2|     1.5828088061289902|\n",
      "|2018|    3|     1.5889266575514391|\n",
      "|2018|    4|     1.5892638003356951|\n",
      "|2018|    5|     1.5853707794307341|\n",
      "|2018|    6|      1.586684025254753|\n",
      "|2018|    7|     1.5937331683007299|\n",
      "|2018|    8|     1.5902972619869418|\n",
      "|2018|    9|     1.5784291587513244|\n",
      "|2018|   10|     1.5640660108629865|\n",
      "|2018|   11|     1.5717419465331057|\n",
      "|2018|   12|     1.5884660642357376|\n",
      "+----+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT year\n",
    "    ,month\n",
    "    ,AVG(passenger_count) AS avg_passengers_per_trip\n",
    "FROM nyc_taxi_data_2017_18\n",
    "GROUP BY year\n",
    "    ,month\n",
    "ORDER BY year\n",
    "    ,month\n",
    "\"\"\").show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.d. For each year and month: What was the average amount paid per trip (total_amount)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------------------+\n",
      "|year|month|avg_total_amount_per_trip|\n",
      "+----+-----+-------------------------+\n",
      "|2017|    1|        15.30173950320955|\n",
      "|2017|    2|       15.470210002462021|\n",
      "|2017|    3|        16.00380195564449|\n",
      "|2017|    4|        16.10720418329613|\n",
      "|2017|    5|       16.560673703888867|\n",
      "|2017|    6|        16.47228243213232|\n",
      "|2017|    7|         16.2144495542399|\n",
      "|2017|    8|        16.30985790548921|\n",
      "|2017|    9|       16.515653416610583|\n",
      "|2017|   10|       16.576218103559412|\n",
      "|2017|   11|        16.32591823573312|\n",
      "|2017|   12|       16.032728606820424|\n",
      "|2018|    1|        15.38746873304433|\n",
      "|2018|    2|       15.387113757366647|\n",
      "|2018|    3|       15.901031332181095|\n",
      "|2018|    4|       16.261353141312924|\n",
      "|2018|    5|       16.755073060361443|\n",
      "|2018|    6|       16.653265007935776|\n",
      "|2018|    7|       16.569750328297385|\n",
      "|2018|    8|       16.601714209171014|\n",
      "|2018|    9|       16.834233158417458|\n",
      "|2018|   10|       16.933848321180925|\n",
      "|2018|   11|       16.818571270466034|\n",
      "|2018|   12|       16.470735408327634|\n",
      "+----+-----+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT year\n",
    "    ,month\n",
    "    ,AVG(total_amount) AS avg_total_amount_per_trip\n",
    "FROM nyc_taxi_data_2017_18\n",
    "GROUP BY year\n",
    "    ,month\n",
    "ORDER BY year\n",
    "    ,month\n",
    "\"\"\").show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.d. For each year and month: What was the average amount paid per passenger (total_amount)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------------------+\n",
      "|year|month|avg_total_amount_per_passenger|\n",
      "+----+-----+------------------------------+\n",
      "|2017|    1|            12.646149725201287|\n",
      "|2017|    2|            12.764816082660923|\n",
      "|2017|    3|            13.245625458581475|\n",
      "|2017|    4|            13.265101183416846|\n",
      "|2017|    5|            13.651144429622907|\n",
      "|2017|    6|            13.604502486696209|\n",
      "|2017|    7|            13.287119010142096|\n",
      "|2017|    8|             13.39625704158913|\n",
      "|2017|    9|            13.590143123322886|\n",
      "|2017|   10|             13.68152108161739|\n",
      "|2017|   11|            13.480742929428729|\n",
      "|2017|   12|            13.117433840563063|\n",
      "|2018|    1|            12.735796628332748|\n",
      "|2018|    2|            12.776375687262949|\n",
      "|2018|    3|            13.154252048935492|\n",
      "|2018|    4|            13.445791517382709|\n",
      "|2018|    5|             13.87456607832239|\n",
      "|2018|    6|            13.777108741419482|\n",
      "|2018|    7|            13.682049332549617|\n",
      "|2018|    8|            13.717627626053176|\n",
      "|2018|    9|            13.958107445881346|\n",
      "|2018|   10|            14.096704885521154|\n",
      "|2018|   11|            13.980369209989615|\n",
      "|2018|   12|            13.577776159503674|\n",
      "+----+-----+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT year\n",
    "    ,month\n",
    "    ,AVG(total_amount / passenger_count) AS avg_total_amount_per_passenger\n",
    "FROM nyc_taxi_data_2017_18\n",
    "GROUP BY year\n",
    "    ,month\n",
    "ORDER BY year\n",
    "    ,month\n",
    "\"\"\").show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.a. For each taxi colour (yellow and green): What was the average, median, minimum and maximum trip duration in seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------------+----------------------------+-------------------------+-------------------------+\n",
      "|taxi_type|avg_trip_duration_seconds|median_trip_duration_seconds|min_trip_duration_seconds|max_trip_duration_seconds|\n",
      "+---------+-------------------------+----------------------------+-------------------------+-------------------------+\n",
      "|    green|       1266.2004888441165|                       627.0|                        1|                   202989|\n",
      "|   yellow|       1022.0828914491414|                       670.0|                        1|                 45466304|\n",
      "+---------+-------------------------+----------------------------+-------------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT taxi_type\n",
    "    ,AVG(trip_duration_seconds) AS avg_trip_duration_seconds\n",
    "    ,PERCENTILE(trip_duration_seconds, 0.5) AS median_trip_duration_seconds\n",
    "    ,MIN(trip_duration_seconds) AS min_trip_duration_seconds\n",
    "    ,MAX(trip_duration_seconds) AS max_trip_duration_seconds\n",
    "FROM nyc_taxi_data_2017_18\n",
    "GROUP BY taxi_type\n",
    "\"\"\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.b. For each taxi colour (yellow and green): What was the average, median, minimum and maximum trip distance in km?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`trip_distance_km`' given input columns: [nyc_taxi_data_2017_18.fare_amount, nyc_taxi_data_2017_18.passenger_count, nyc_taxi_data_2017_18.pickup_location_id, nyc_taxi_data_2017_18.month, nyc_taxi_data_2017_18.payment_type, nyc_taxi_data_2017_18.pickup_hour, nyc_taxi_data_2017_18.dropoff_datetime, nyc_taxi_data_2017_18.ehail_fee, nyc_taxi_data_2017_18.total_amount, nyc_taxi_data_2017_18.dropoff_location_id, nyc_taxi_data_2017_18.store_and_fwd_flag, nyc_taxi_data_2017_18.trip_distance, nyc_taxi_data_2017_18.dropoff_service_zone, nyc_taxi_data_2017_18.trip_duration_category, nyc_taxi_data_2017_18.extra, nyc_taxi_data_2017_18.trip_duration_seconds, nyc_taxi_data_2017_18.from_airport, nyc_taxi_data_2017_18.improvement_surcharge, nyc_taxi_data_2017_18.year, nyc_taxi_data_2017_18.taxi_type, nyc_taxi_data_2017_18.RatecodeID, nyc_taxi_data_2017_18.pickup_datetime, nyc_taxi_data_2017_18.tolls_amount, nyc_taxi_data_2017_18.pickup_service_zone, nyc_taxi_data_2017_18.pickup_borough, nyc_taxi_data_2017_18.mta_tax, nyc_taxi_data_2017_18.dropoff_borough, nyc_taxi_data_2017_18.VendorID, nyc_taxi_data_2017_18.tip_amount, nyc_taxi_data_2017_18.to_airport, nyc_taxi_data_2017_18.trip_type]; line 3 pos 9;\\n'Aggregate [taxi_type#19], [taxi_type#19, 'AVG('trip_distance_km) AS avg_trip_distance_km#469, 'PERCENTILE('trip_distance_km, 0.5) AS median_trip_distance_km#470, 'MIN('trip_distance_km) AS min_trip_distance_km#471, 'MAX('trip_distance_km) AS max_trip_distance_km#472]\\n+- SubqueryAlias `nyc_taxi_data_2017_18`\\n   +- Relation[VendorID#0,pickup_datetime#1,dropoff_datetime#2,passenger_count#3,trip_distance#4,pickup_location_id#5,dropoff_location_id#6,RatecodeID#7,store_and_fwd_flag#8,payment_type#9,fare_amount#10,extra#11,mta_tax#12,improvement_surcharge#13,tip_amount#14,tolls_amount#15,ehail_fee#16,total_amount#17,trip_type#18,taxi_type#19,pickup_service_zone#20,pickup_borough#21,dropoff_service_zone#22,dropoff_borough#23,trip_duration_seconds#24L,trip_duration_category#25,pickup_hour#26,from_airport#27,to_airport#28,year#29,month#30] parquet\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o25.sql.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`trip_distance_km`' given input columns: [nyc_taxi_data_2017_18.fare_amount, nyc_taxi_data_2017_18.passenger_count, nyc_taxi_data_2017_18.pickup_location_id, nyc_taxi_data_2017_18.month, nyc_taxi_data_2017_18.payment_type, nyc_taxi_data_2017_18.pickup_hour, nyc_taxi_data_2017_18.dropoff_datetime, nyc_taxi_data_2017_18.ehail_fee, nyc_taxi_data_2017_18.total_amount, nyc_taxi_data_2017_18.dropoff_location_id, nyc_taxi_data_2017_18.store_and_fwd_flag, nyc_taxi_data_2017_18.trip_distance, nyc_taxi_data_2017_18.dropoff_service_zone, nyc_taxi_data_2017_18.trip_duration_category, nyc_taxi_data_2017_18.extra, nyc_taxi_data_2017_18.trip_duration_seconds, nyc_taxi_data_2017_18.from_airport, nyc_taxi_data_2017_18.improvement_surcharge, nyc_taxi_data_2017_18.year, nyc_taxi_data_2017_18.taxi_type, nyc_taxi_data_2017_18.RatecodeID, nyc_taxi_data_2017_18.pickup_datetime, nyc_taxi_data_2017_18.tolls_amount, nyc_taxi_data_2017_18.pickup_service_zone, nyc_taxi_data_2017_18.pickup_borough, nyc_taxi_data_2017_18.mta_tax, nyc_taxi_data_2017_18.dropoff_borough, nyc_taxi_data_2017_18.VendorID, nyc_taxi_data_2017_18.tip_amount, nyc_taxi_data_2017_18.to_airport, nyc_taxi_data_2017_18.trip_type]; line 3 pos 9;\n'Aggregate [taxi_type#19], [taxi_type#19, 'AVG('trip_distance_km) AS avg_trip_distance_km#469, 'PERCENTILE('trip_distance_km, 0.5) AS median_trip_distance_km#470, 'MIN('trip_distance_km) AS min_trip_distance_km#471, 'MAX('trip_distance_km) AS max_trip_distance_km#472]\n+- SubqueryAlias `nyc_taxi_data_2017_18`\n   +- Relation[VendorID#0,pickup_datetime#1,dropoff_datetime#2,passenger_count#3,trip_distance#4,pickup_location_id#5,dropoff_location_id#6,RatecodeID#7,store_and_fwd_flag#8,payment_type#9,fare_amount#10,extra#11,mta_tax#12,improvement_surcharge#13,tip_amount#14,tolls_amount#15,ehail_fee#16,total_amount#17,trip_type#18,taxi_type#19,pickup_service_zone#20,pickup_borough#21,dropoff_service_zone#22,dropoff_borough#23,trip_duration_seconds#24L,trip_duration_category#25,pickup_hour#26,from_airport#27,to_airport#28,year#29,month#30] parquet\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$mapChild$2(TreeNode.scala:297)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$13.apply(TreeNode.scala:356)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:356)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e4cbc49bbdb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mFROM\u001b[0m \u001b[0mnyc_taxi_data_2017_18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mGROUP\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mtaxi_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \"\"\").show(2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`trip_distance_km`' given input columns: [nyc_taxi_data_2017_18.fare_amount, nyc_taxi_data_2017_18.passenger_count, nyc_taxi_data_2017_18.pickup_location_id, nyc_taxi_data_2017_18.month, nyc_taxi_data_2017_18.payment_type, nyc_taxi_data_2017_18.pickup_hour, nyc_taxi_data_2017_18.dropoff_datetime, nyc_taxi_data_2017_18.ehail_fee, nyc_taxi_data_2017_18.total_amount, nyc_taxi_data_2017_18.dropoff_location_id, nyc_taxi_data_2017_18.store_and_fwd_flag, nyc_taxi_data_2017_18.trip_distance, nyc_taxi_data_2017_18.dropoff_service_zone, nyc_taxi_data_2017_18.trip_duration_category, nyc_taxi_data_2017_18.extra, nyc_taxi_data_2017_18.trip_duration_seconds, nyc_taxi_data_2017_18.from_airport, nyc_taxi_data_2017_18.improvement_surcharge, nyc_taxi_data_2017_18.year, nyc_taxi_data_2017_18.taxi_type, nyc_taxi_data_2017_18.RatecodeID, nyc_taxi_data_2017_18.pickup_datetime, nyc_taxi_data_2017_18.tolls_amount, nyc_taxi_data_2017_18.pickup_service_zone, nyc_taxi_data_2017_18.pickup_borough, nyc_taxi_data_2017_18.mta_tax, nyc_taxi_data_2017_18.dropoff_borough, nyc_taxi_data_2017_18.VendorID, nyc_taxi_data_2017_18.tip_amount, nyc_taxi_data_2017_18.to_airport, nyc_taxi_data_2017_18.trip_type]; line 3 pos 9;\\n'Aggregate [taxi_type#19], [taxi_type#19, 'AVG('trip_distance_km) AS avg_trip_distance_km#469, 'PERCENTILE('trip_distance_km, 0.5) AS median_trip_distance_km#470, 'MIN('trip_distance_km) AS min_trip_distance_km#471, 'MAX('trip_distance_km) AS max_trip_distance_km#472]\\n+- SubqueryAlias `nyc_taxi_data_2017_18`\\n   +- Relation[VendorID#0,pickup_datetime#1,dropoff_datetime#2,passenger_count#3,trip_distance#4,pickup_location_id#5,dropoff_location_id#6,RatecodeID#7,store_and_fwd_flag#8,payment_type#9,fare_amount#10,extra#11,mta_tax#12,improvement_surcharge#13,tip_amount#14,tolls_amount#15,ehail_fee#16,total_amount#17,trip_type#18,taxi_type#19,pickup_service_zone#20,pickup_borough#21,dropoff_service_zone#22,dropoff_borough#23,trip_duration_seconds#24L,trip_duration_category#25,pickup_hour#26,from_airport#27,to_airport#28,year#29,month#30] parquet\\n\""
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT taxi_type\n",
    "    ,AVG(trip_distance_km) AS avg_trip_distance_km\n",
    "    ,PERCENTILE(trip_distance_km, 0.5) AS median_trip_distance_km\n",
    "    ,MIN(trip_distance_km) AS min_trip_distance_km\n",
    "    ,MAX(trip_distance_km) AS max_trip_distance_km\n",
    "FROM nyc_taxi_data_2017_18\n",
    "GROUP BY taxi_type\n",
    "\"\"\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.c. For each taxi colour (yellow and green): What was the average, median, minimum and maximum speed in km per hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT taxi_type\n",
    "    ,AVG(trip_distance_km/(trip_duration_seconds / 3600)) AS avg_km_per_hour\n",
    "    ,PERCENTILE(trip_distance_km/(trip_duration_seconds / 3600), 0.5) AS median_km_per_hour\n",
    "    ,MIN(trip_distance_km/(trip_duration_seconds / 3600)) AS min_km_per_hour\n",
    "    ,MAX(trip_distance_km/(trip_duration_seconds / 3600)) AS max_km_per_hour\n",
    "FROM nyc_taxi_data_2017_18\n",
    "GROUP BY taxi_type\n",
    "\"\"\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.d. For each taxi colour (yellow and green): What was the percentage of trips where the driver received tips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|pct_trips_with_tip|\n",
      "+------------------+\n",
      "| 63.05336311357655|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT ((SELECT COUNT(*) FROM nyc_taxi_data_2017_18 WHERE tip_amount > 0) / COUNT(*)) * 100 AS pct_trips_with_tip\n",
    "FROM nyc_taxi_data_2017_18\n",
    "\"\"\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. For trips where the driver received tips, What was the percentage where the driver received tips of at least $10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|pct_trips_top_gt_10|\n",
      "+-------------------+\n",
      "| 2.1053562129901136|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT ((SELECT COUNT(*) FROM nyc_taxi_data_2017_18 WHERE tip_amount >= 10) / COUNT(*)) * 100 AS pct_trips_top_gt_10\n",
    "FROM nyc_taxi_data_2017_18\n",
    "\"\"\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.a. For each duration bin calculate: Average speed (km per hour)\n",
    "Bins are Under 5 Mins, From 5 mins to 10 mins, From 10 mins to 20 mins, From 20 mins to 30 mins, At least 30 mins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`trip_distance_km`' given input columns: [nyc_taxi_data_2017_18.fare_amount, nyc_taxi_data_2017_18.passenger_count, nyc_taxi_data_2017_18.pickup_location_id, nyc_taxi_data_2017_18.month, nyc_taxi_data_2017_18.payment_type, nyc_taxi_data_2017_18.pickup_hour, nyc_taxi_data_2017_18.dropoff_datetime, nyc_taxi_data_2017_18.ehail_fee, nyc_taxi_data_2017_18.total_amount, nyc_taxi_data_2017_18.dropoff_location_id, nyc_taxi_data_2017_18.store_and_fwd_flag, nyc_taxi_data_2017_18.trip_distance, nyc_taxi_data_2017_18.dropoff_service_zone, nyc_taxi_data_2017_18.trip_duration_category, nyc_taxi_data_2017_18.extra, nyc_taxi_data_2017_18.trip_duration_seconds, nyc_taxi_data_2017_18.from_airport, nyc_taxi_data_2017_18.improvement_surcharge, nyc_taxi_data_2017_18.year, nyc_taxi_data_2017_18.taxi_type, nyc_taxi_data_2017_18.RatecodeID, nyc_taxi_data_2017_18.pickup_datetime, nyc_taxi_data_2017_18.tolls_amount, nyc_taxi_data_2017_18.pickup_service_zone, nyc_taxi_data_2017_18.pickup_borough, nyc_taxi_data_2017_18.mta_tax, nyc_taxi_data_2017_18.dropoff_borough, nyc_taxi_data_2017_18.VendorID, nyc_taxi_data_2017_18.tip_amount, nyc_taxi_data_2017_18.to_airport, nyc_taxi_data_2017_18.trip_type]; line 3 pos 9;\\n'Aggregate [trip_duration_category#25], [trip_duration_category#25, 'AVG(('trip_distance_km / (cast(trip_duration_seconds#24L as double) / cast(3600 as double)))) AS avg_km_per_hour#213]\\n+- SubqueryAlias `nyc_taxi_data_2017_18`\\n   +- Relation[VendorID#0,pickup_datetime#1,dropoff_datetime#2,passenger_count#3,trip_distance#4,pickup_location_id#5,dropoff_location_id#6,RatecodeID#7,store_and_fwd_flag#8,payment_type#9,fare_amount#10,extra#11,mta_tax#12,improvement_surcharge#13,tip_amount#14,tolls_amount#15,ehail_fee#16,total_amount#17,trip_type#18,taxi_type#19,pickup_service_zone#20,pickup_borough#21,dropoff_service_zone#22,dropoff_borough#23,trip_duration_seconds#24L,trip_duration_category#25,pickup_hour#26,from_airport#27,to_airport#28,year#29,month#30] parquet\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o25.sql.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`trip_distance_km`' given input columns: [nyc_taxi_data_2017_18.fare_amount, nyc_taxi_data_2017_18.passenger_count, nyc_taxi_data_2017_18.pickup_location_id, nyc_taxi_data_2017_18.month, nyc_taxi_data_2017_18.payment_type, nyc_taxi_data_2017_18.pickup_hour, nyc_taxi_data_2017_18.dropoff_datetime, nyc_taxi_data_2017_18.ehail_fee, nyc_taxi_data_2017_18.total_amount, nyc_taxi_data_2017_18.dropoff_location_id, nyc_taxi_data_2017_18.store_and_fwd_flag, nyc_taxi_data_2017_18.trip_distance, nyc_taxi_data_2017_18.dropoff_service_zone, nyc_taxi_data_2017_18.trip_duration_category, nyc_taxi_data_2017_18.extra, nyc_taxi_data_2017_18.trip_duration_seconds, nyc_taxi_data_2017_18.from_airport, nyc_taxi_data_2017_18.improvement_surcharge, nyc_taxi_data_2017_18.year, nyc_taxi_data_2017_18.taxi_type, nyc_taxi_data_2017_18.RatecodeID, nyc_taxi_data_2017_18.pickup_datetime, nyc_taxi_data_2017_18.tolls_amount, nyc_taxi_data_2017_18.pickup_service_zone, nyc_taxi_data_2017_18.pickup_borough, nyc_taxi_data_2017_18.mta_tax, nyc_taxi_data_2017_18.dropoff_borough, nyc_taxi_data_2017_18.VendorID, nyc_taxi_data_2017_18.tip_amount, nyc_taxi_data_2017_18.to_airport, nyc_taxi_data_2017_18.trip_type]; line 3 pos 9;\n'Aggregate [trip_duration_category#25], [trip_duration_category#25, 'AVG(('trip_distance_km / (cast(trip_duration_seconds#24L as double) / cast(3600 as double)))) AS avg_km_per_hour#213]\n+- SubqueryAlias `nyc_taxi_data_2017_18`\n   +- Relation[VendorID#0,pickup_datetime#1,dropoff_datetime#2,passenger_count#3,trip_distance#4,pickup_location_id#5,dropoff_location_id#6,RatecodeID#7,store_and_fwd_flag#8,payment_type#9,fare_amount#10,extra#11,mta_tax#12,improvement_surcharge#13,tip_amount#14,tolls_amount#15,ehail_fee#16,total_amount#17,trip_type#18,taxi_type#19,pickup_service_zone#20,pickup_borough#21,dropoff_service_zone#22,dropoff_borough#23,trip_duration_seconds#24L,trip_duration_category#25,pickup_hour#26,from_airport#27,to_airport#28,year#29,month#30] parquet\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$mapChild$2(TreeNode.scala:297)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$13.apply(TreeNode.scala:356)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:356)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7a54aee8a8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mFROM\u001b[0m \u001b[0mnyc_taxi_data_2017_18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mGROUP\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mtrip_duration_category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \"\"\").show(5)\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`trip_distance_km`' given input columns: [nyc_taxi_data_2017_18.fare_amount, nyc_taxi_data_2017_18.passenger_count, nyc_taxi_data_2017_18.pickup_location_id, nyc_taxi_data_2017_18.month, nyc_taxi_data_2017_18.payment_type, nyc_taxi_data_2017_18.pickup_hour, nyc_taxi_data_2017_18.dropoff_datetime, nyc_taxi_data_2017_18.ehail_fee, nyc_taxi_data_2017_18.total_amount, nyc_taxi_data_2017_18.dropoff_location_id, nyc_taxi_data_2017_18.store_and_fwd_flag, nyc_taxi_data_2017_18.trip_distance, nyc_taxi_data_2017_18.dropoff_service_zone, nyc_taxi_data_2017_18.trip_duration_category, nyc_taxi_data_2017_18.extra, nyc_taxi_data_2017_18.trip_duration_seconds, nyc_taxi_data_2017_18.from_airport, nyc_taxi_data_2017_18.improvement_surcharge, nyc_taxi_data_2017_18.year, nyc_taxi_data_2017_18.taxi_type, nyc_taxi_data_2017_18.RatecodeID, nyc_taxi_data_2017_18.pickup_datetime, nyc_taxi_data_2017_18.tolls_amount, nyc_taxi_data_2017_18.pickup_service_zone, nyc_taxi_data_2017_18.pickup_borough, nyc_taxi_data_2017_18.mta_tax, nyc_taxi_data_2017_18.dropoff_borough, nyc_taxi_data_2017_18.VendorID, nyc_taxi_data_2017_18.tip_amount, nyc_taxi_data_2017_18.to_airport, nyc_taxi_data_2017_18.trip_type]; line 3 pos 9;\\n'Aggregate [trip_duration_category#25], [trip_duration_category#25, 'AVG(('trip_distance_km / (cast(trip_duration_seconds#24L as double) / cast(3600 as double)))) AS avg_km_per_hour#213]\\n+- SubqueryAlias `nyc_taxi_data_2017_18`\\n   +- Relation[VendorID#0,pickup_datetime#1,dropoff_datetime#2,passenger_count#3,trip_distance#4,pickup_location_id#5,dropoff_location_id#6,RatecodeID#7,store_and_fwd_flag#8,payment_type#9,fare_amount#10,extra#11,mta_tax#12,improvement_surcharge#13,tip_amount#14,tolls_amount#15,ehail_fee#16,total_amount#17,trip_type#18,taxi_type#19,pickup_service_zone#20,pickup_borough#21,dropoff_service_zone#22,dropoff_borough#23,trip_duration_seconds#24L,trip_duration_category#25,pickup_hour#26,from_airport#27,to_airport#28,year#29,month#30] parquet\\n\""
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT trip_duration_category\n",
    "    ,AVG(trip_distance_km / (trip_duration_seconds / 3600)) AS avg_km_per_hour\n",
    "FROM nyc_taxi_data_2017_18\n",
    "GROUP BY trip_duration_category\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.b. For each duration bin calculate: Average distance per dollar (km per $)\n",
    "Bins are Under 5 Mins, From 5 mins to 10 mins, From 10 mins to 20 mins, From 20 mins to 30 mins, At least 30 mins.\n",
    "\n",
    "Assuming total US dollars received for journey, which includes tips, special fees and taxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT trip_duration_category\n",
    "    ,AVG(trip_distance_km / total_amount) AS avg_distance\n",
    "FROM nyc_taxi_data_2017_18\n",
    "GROUP BY trip_duration_category\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Which duration bin will you advise a taxi driver to target to maximise his income?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
